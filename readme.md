# Network Security Phishing Detection Pipeline

## Project Structure
```phishing_detection/
â”œâ”€â”€ app.py                     # FastAPI application for training and prediction APIs
â”œâ”€â”€ main.py                    # Script to run the full pipeline (training and preprocessing)
â”œâ”€â”€ predict.py                 # Prediction pipeline logic
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html             # HTML template for the web interface
â”‚   â”œâ”€â”€ table.html            # HTML template for displaying prediction results
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ __init__.py            # Initialization file for the ml module
â”‚   â”œâ”€â”€ ingestion.py           # Data ingestion logic
â”‚   â”œâ”€â”€ validation.py          # Data validation logic
â”‚   â”œâ”€â”€ transformation.py      # Data transformation logic
â”‚   â”œâ”€â”€ training.py            # Model training logic
â”‚   â”œâ”€â”€ utils.py               # Utility functions (e.g., logging, object loading)
â”‚   â”œâ”€â”€ config.py              # Configuration file for paths and constants
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ model.pkl              # Trained model file
â”‚   â”œâ”€â”€ preprocessor.pkl       # Preprocessor file
â”œâ”€â”€ predictions_output/
â”‚   â”œâ”€â”€ output.csv             # Output predictions from the prediction pipeline
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ README.md                  # Project documentation
â”œâ”€â”€ .env                       # Environment variables (e.g., MLflow tracking URI, MONGODB URI,etc.)
```

## Project Flowchart
User Interaction (Frontend)
    â”œâ”€â”€ Upload CSV File (index.html)
    â”œâ”€â”€ Trigger Prediction (/predict API)
    â””â”€â”€ Trigger Training (/train API)
          â†“
FastAPI Backend (app.py)
    â”œâ”€â”€ /predict Route
    â”‚   â”œâ”€â”€ Calls predict_new_data() in predict.py
    â”‚   â”œâ”€â”€ Loads Model and Preprocessor
    â”‚   â”œâ”€â”€ Preprocesses Input Data
    â”‚   â””â”€â”€ Returns Predictions
    â””â”€â”€ /train Route
        â”œâ”€â”€ Calls Full Pipeline
        â”‚   â”œâ”€â”€ ingest_data() (ingestion.py)
        â”‚   â”œâ”€â”€ validate_data() (validation.py)
        â”‚   â”œâ”€â”€ transform_data() (transformation.py)
        â”‚   â””â”€â”€ train_model() (training.py)
        â””â”€â”€ Saves Model and Preprocessor
## Setup

1. **Clone** & `cd networksecurity_cleaned`
2. **Fill** `.env` with your MongoDB & MLflow/DagsHub creds.
3. `pip install -r requirements.txt`
4. `python main.py`

## Docker

```bash
docker build -t networksec-pipeline .
docker run --env-file .env networksec-pipeline
```

# ğŸ§  End-to-End ML Project

This is a complete machine learning pipeline from data ingestion to model deployment.

---

## ğŸ“ Project Structure

- `ml/` â€” Modular Python scripts for data handling, transformation, training, and validation  
- `data/` â€” Raw and processed datasets  
- `data/` â€” Trained models, preprocessor  
- `logs/` - log files
- `experiments.ipynb` â€” Notebook for interactive experimentation  
- `.env` â€” Environment variables for credentials  
- `predict.py` â€” Script to run predictions on new data
- `main.py` - Common execution point that triggers the entire project
- `app.py` - 
---

## ğŸš€ Setup Instructions

1. **Clone the repo**  
```bash
git clone <repo-url>
cd <project-folder>
```

2. **Create a virtual environment**
``` bash
python -m venv venv
source venv/bin/activate
```
3. **Install dependencies**

```bash
pip install -r requirements.txt
```
4. **Run the pipeline**
``` bash
python main.py
```

## ğŸ§ª MLflow Tracking
All experiments are tracked using MLflow and DagsHub:

DagsHub MLflow UI

## ğŸ§ª Model Inference
```bash
python predict.py
```
## ğŸ“Š Monitoring & Drift
Drift report available in drift_report.yaml.

## ğŸ“¦ Deployment
Deployment planned via FastAPI and render

## Flowchart to describe the flow of project
User Interaction (Frontend)
    â”œâ”€â”€ Upload CSV File (index.html)
    â”œâ”€â”€ Trigger Prediction (/predict API)
    â””â”€â”€ Trigger Training (/train API)
          â†“
FastAPI Backend (app.py)
    â”œâ”€â”€ /predict Route
    â”‚   â”œâ”€â”€ Calls predict_new_data() in predict.py
    â”‚   â”œâ”€â”€ Loads Model and Preprocessor
    â”‚   â”œâ”€â”€ Preprocesses Input Data
    â”‚   â””â”€â”€ Returns Predictions
    â””â”€â”€ /train Route
        â”œâ”€â”€ Calls Full Pipeline
        â”‚   â”œâ”€â”€ ingest_data() (ingestion.py)
        â”‚   â”œâ”€â”€ validate_data() (validation.py)
        â”‚   â”œâ”€â”€ transform_data() (transformation.py)
        â”‚   â””â”€â”€ train_model() (training.py)
        â””â”€â”€ Saves Model and Preprocessor